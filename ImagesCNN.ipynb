{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Conv2D, Activation, Flatten, Dense\n",
    "from keras.layers import (concatenate)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "data_image = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisnärvivõrgud\\\\data\\\\train_images\"\n",
    "data_dir = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisnärvivõrgud\\\\data\"\n",
    "\n",
    "label_column = \"AdoptionSpeed\"\n",
    "\n",
    "\n",
    "test_size = 0.2\n",
    "height, width = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), sep=',')\n",
    "pet_ids = train[\"PetID\"]\n",
    "\n",
    "selected_columns = [\"Type\",\n",
    "                    \"Gender\",\n",
    "                    \"Color1\",\n",
    "                    \"Color2\",\n",
    "                    \"Color3\",\n",
    "                    \"MaturitySize\",\n",
    "                    \"FurLength\",\n",
    "                    \"Vaccinated\",\n",
    "                    \"Dewormed\",\n",
    "                    \"Sterilized\",\n",
    "                    \"Health\",\n",
    "                    \"State\",\n",
    "                    \"MaturitySize\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = train[label_column]\n",
    "\n",
    "# One-Hot-encode\n",
    "X = pd.get_dummies(train[selected_columns], columns=selected_columns)\n",
    "\n",
    "# Normalize:\n",
    "to_normalize = [\"Age\", \"Fee\", \"Quantity\"]\n",
    "for to_norm in to_normalize:\n",
    "     X[to_norm] = (train[to_norm] - train[to_norm].mean()) / train[to_norm].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 14993/14993 [08:55<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "f_im_name = \"images.binary\"\n",
    "\n",
    "if not os.path.isfile(f_im_name):\n",
    "    \n",
    "    image_paths = [os.path.join(data_dir, data_image, pet_id + \"-1.jpg\") for pet_id in pet_ids]\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for path in tqdm(image_paths):\n",
    "        if os.path.isfile(path):\n",
    "            image = Image.open(path).convert(\"RGB\") \n",
    "            image.load()\n",
    "            image = np.asarray(image, dtype=\"int32\" )\n",
    "            image = resize(image, (height, width), anti_aliasing=True, mode='constant')\n",
    "        else:\n",
    "            image = np.random.rand(height, width, 3) * 255\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    images = np.array(images)\n",
    "\n",
    "    # Standardize:\n",
    "    mean = np.mean(images)\n",
    "    std = np.std(images)\n",
    "\n",
    "    images_meanstd = (images - mean)/std\n",
    "    with open(f_im_name, 'wb') as handle:\n",
    "        pickle.dump(images_meanstd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(f_im_name, 'rb') as handle:\n",
    "        images_meanstd = pickle.load(handle)\n",
    "\n",
    "print(images_meanstd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, X_train_else, X_test_else, y_train, y_test = train_test_split(images_meanstd, \n",
    "                                                                                       X, \n",
    "                                                                                       y, \n",
    "                                                                                       test_size=0.95,\n",
    "                                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 599 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "599/599 [==============================] - ETA: 19:41 - loss: 2.4950 - acc: 0.0000e+ - ETA: 10:23 - loss: 1.9725 - acc: 0.0625   - ETA: 7:16 - loss: 3.0660 - acc: 0.0833 - ETA: 5:43 - loss: 3.0095 - acc: 0.125 - ETA: 4:47 - loss: 2.8213 - acc: 0.125 - ETA: 4:07 - loss: 2.6288 - acc: 0.145 - ETA: 3:39 - loss: 3.7638 - acc: 0.125 - ETA: 3:16 - loss: 3.5414 - acc: 0.156 - ETA: 2:57 - loss: 3.8876 - acc: 0.152 - ETA: 2:43 - loss: 3.8477 - acc: 0.175 - ETA: 2:32 - loss: 3.7287 - acc: 0.193 - ETA: 2:22 - loss: 3.8092 - acc: 0.197 - ETA: 2:13 - loss: 3.6164 - acc: 0.211 - ETA: 2:05 - loss: 3.5179 - acc: 0.214 - ETA: 1:59 - loss: 3.3811 - acc: 0.225 - ETA: 1:53 - loss: 3.2769 - acc: 0.218 - ETA: 1:47 - loss: 3.1692 - acc: 0.213 - ETA: 1:43 - loss: 3.0895 - acc: 0.222 - ETA: 1:40 - loss: 3.0192 - acc: 0.223 - ETA: 1:36 - loss: 2.9538 - acc: 0.225 - ETA: 1:33 - loss: 2.9300 - acc: 0.232 - ETA: 1:29 - loss: 2.8609 - acc: 0.244 - ETA: 1:26 - loss: 2.8046 - acc: 0.255 - ETA: 1:23 - loss: 2.7860 - acc: 0.244 - ETA: 1:20 - loss: 2.7512 - acc: 0.240 - ETA: 1:17 - loss: 2.7071 - acc: 0.240 - ETA: 1:14 - loss: 2.6629 - acc: 0.245 - ETA: 1:11 - loss: 2.6225 - acc: 0.236 - ETA: 1:08 - loss: 2.5924 - acc: 0.237 - ETA: 1:06 - loss: 2.5674 - acc: 0.237 - ETA: 1:04 - loss: 2.5262 - acc: 0.246 - ETA: 1:01 - loss: 2.4941 - acc: 0.250 - ETA: 59s - loss: 2.4603 - acc: 0.253 - ETA: 57s - loss: 2.4323 - acc: 0.25 - ETA: 55s - loss: 2.4154 - acc: 0.24 - ETA: 53s - loss: 2.4060 - acc: 0.23 - ETA: 51s - loss: 2.3805 - acc: 0.23 - ETA: 49s - loss: 2.3589 - acc: 0.23 - ETA: 47s - loss: 2.3382 - acc: 0.24 - ETA: 45s - loss: 2.3124 - acc: 0.24 - ETA: 44s - loss: 2.2923 - acc: 0.25 - ETA: 42s - loss: 2.2712 - acc: 0.25 - ETA: 40s - loss: 2.2538 - acc: 0.25 - ETA: 39s - loss: 2.2413 - acc: 0.24 - ETA: 37s - loss: 2.2235 - acc: 0.24 - ETA: 35s - loss: 2.2117 - acc: 0.24 - ETA: 34s - loss: 2.1933 - acc: 0.25 - ETA: 32s - loss: 2.1765 - acc: 0.25 - ETA: 31s - loss: 2.1618 - acc: 0.25 - ETA: 30s - loss: 2.1456 - acc: 0.26 - ETA: 28s - loss: 2.1349 - acc: 0.25 - ETA: 27s - loss: 2.1203 - acc: 0.25 - ETA: 26s - loss: 2.1140 - acc: 0.25 - ETA: 24s - loss: 2.0987 - acc: 0.25 - ETA: 23s - loss: 2.0846 - acc: 0.25 - ETA: 22s - loss: 2.0765 - acc: 0.25 - ETA: 20s - loss: 2.0619 - acc: 0.25 - ETA: 19s - loss: 2.0542 - acc: 0.25 - ETA: 18s - loss: 2.0454 - acc: 0.26 - ETA: 17s - loss: 2.0360 - acc: 0.26 - ETA: 15s - loss: 2.0339 - acc: 0.25 - ETA: 14s - loss: 2.0231 - acc: 0.26 - ETA: 13s - loss: 2.0148 - acc: 0.25 - ETA: 12s - loss: 2.0036 - acc: 0.26 - ETA: 11s - loss: 1.9948 - acc: 0.26 - ETA: 9s - loss: 1.9860 - acc: 0.2633 - ETA: 8s - loss: 1.9754 - acc: 0.264 - ETA: 7s - loss: 1.9663 - acc: 0.266 - ETA: 6s - loss: 1.9590 - acc: 0.264 - ETA: 5s - loss: 1.9512 - acc: 0.260 - ETA: 4s - loss: 1.9511 - acc: 0.260 - ETA: 3s - loss: 1.9450 - acc: 0.260 - ETA: 2s - loss: 1.9400 - acc: 0.260 - ETA: 0s - loss: 1.9329 - acc: 0.261 - 98s 164ms/step - loss: 1.9269 - acc: 0.2638 - val_loss: 1.4742 - val_acc: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49618986/neural-network-in-keras-with-two-different-input-types-images-and-values\n",
    "# https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "transfer = ResNet50(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
    "\n",
    "# Freeze ResNet50\n",
    "for layer in transfer.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Inputs\n",
    "image_input = Input(shape=(height, width, 3))\n",
    "aux_input = Input(shape=(len(list(X_train_else)),))\n",
    "\n",
    "# Images:\n",
    "transfer = transfer(image_input)\n",
    "transfer = Dense(150, activation='relu')(transfer)\n",
    "flatten = Flatten()(transfer)\n",
    "\n",
    "# Aux input:\n",
    "x = Dense(150, activation='relu')(aux_input)\n",
    "x = Dense(250, activation='relu')(x)\n",
    "x = Dense(350, activation='relu')(x)\n",
    "\n",
    "# Merged:\n",
    "merge = concatenate([flatten, x])\n",
    "x = Dense(500)(merge)\n",
    "x = Dense(450, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "h = Dense(5)(x)\n",
    "\n",
    "# Predictions:\n",
    "predictions = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=[image_input, aux_input], outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit([X_train_img, X_train_else], \n",
    "                    keras.utils.to_categorical(y_train),\n",
    "                    batch_size=8, \n",
    "                    epochs=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_pred = [np.argmax(pred) for pred in model.predict([X_train_img, X_train_else])]\n",
    "test_predictions = [np.argmax(pred) for pred in model.predict([X_test_img, X_test_else])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa on train: 0.0433\n",
      "Accuracy on train: 0.3084\n",
      "________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Kappa on train: {}\".format(round(cohen_kappa_score(y_train, train_pred, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on train: {}\".format(round(accuracy_score(y_train, train_pred), 4)))\n",
    "print(\"________________\")\n",
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_test, test_predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_test, test_predictions), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PetFinderNN)",
   "language": "python",
   "name": "pycharm-b185692d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
