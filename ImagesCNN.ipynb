{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import keras.backend as K\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.applications import Xception\n",
    "from keras.layers import Input, Activation, Flatten, Dense\n",
    "from keras.layers import (concatenate)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "data_image = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisn채rviv천rgud\\\\data\\\\train_images\"\n",
    "data_dir = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisn채rviv천rgud\\\\data\"\n",
    "\n",
    "label_column = \"AdoptionSpeed\"\n",
    "\n",
    "BATCH_SIZE = 256 * 2\n",
    "\n",
    "test_size = 0.2\n",
    "height, width = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow\n",
    "def kappa_loss(y_pred, y_true, y_pow=2, eps=1e-3, N=5, bsize=BATCH_SIZE, name='kappa'):\n",
    "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
    "        Args:\n",
    "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
    "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
    "            y_pow: int,  e.g. y_pow=2\n",
    "            N: typically num_classes of the model\n",
    "            bsize: batch_size of the training or validation ops\n",
    "            eps: a float, prevents divide by zero\n",
    "            name: Optional scope/name for op_scope.\n",
    "        Returns:\n",
    "            A tensor with the kappa loss.\"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        y_true = tf.to_float(y_true)\n",
    "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
    "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
    "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
    "    \n",
    "        pred_ = y_pred ** y_pow\n",
    "        try:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
    "        except Exception:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
    "    \n",
    "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
    "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
    "    \n",
    "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
    "    \n",
    "        nom = tf.reduce_sum(weights * conf_mat)\n",
    "        denom = tf.reduce_sum(weights * tf.matmul(\n",
    "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
    "                              tf.to_float(bsize))\n",
    "    \n",
    "        return nom / (denom + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), sep=',')\n",
    "pet_ids = train[\"PetID\"]\n",
    "\n",
    "selected_columns = [\"Type\",\n",
    "                    \"Gender\",\n",
    "                    \"Color1\",\n",
    "                    \"Color2\",\n",
    "                    \"Color3\",\n",
    "                    \"MaturitySize\",\n",
    "                    \"FurLength\",\n",
    "                    \"Vaccinated\",\n",
    "                    \"Dewormed\",\n",
    "                    \"Sterilized\",\n",
    "                    \"Health\",\n",
    "                    \"State\",\n",
    "                    \"MaturitySize\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = train[label_column]\n",
    "\n",
    "# One-Hot-encode\n",
    "X = pd.get_dummies(train[selected_columns], columns=selected_columns)\n",
    "\n",
    "# Normalize:\n",
    "to_normalize = [\"Age\", \"Fee\", \"Quantity\"]\n",
    "for to_norm in to_normalize:\n",
    "     X[to_norm] = (train[to_norm] - train[to_norm].mean()) / train[to_norm].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "f_im_name = \"images.binary\"\n",
    "\n",
    "if not os.path.isfile(f_im_name):\n",
    "    \n",
    "    image_paths = [os.path.join(data_dir, data_image, pet_id + \"-1.jpg\") for pet_id in pet_ids]\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for path in tqdm(image_paths):\n",
    "        if os.path.isfile(path):\n",
    "            image = Image.open(path).convert(\"RGB\") \n",
    "            image.load()\n",
    "            image = np.asarray(image, dtype=\"int32\" )\n",
    "            image = resize(image, (height, width), anti_aliasing=True, mode='constant')\n",
    "        else:\n",
    "            image = np.random.rand(height, width, 3) * 255\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    images = np.array(images)\n",
    "\n",
    "    # Standardize:\n",
    "    mean = np.mean(images)\n",
    "    std = np.std(images)\n",
    "\n",
    "    images_meanstd = (images - mean)/std\n",
    "    with open(f_im_name, 'wb') as handle:\n",
    "        pickle.dump(images_meanstd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(f_im_name, 'rb') as handle:\n",
    "        images_meanstd = pickle.load(handle)\n",
    "\n",
    "print(images_meanstd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, X_train_else, X_test_else, y_train, y_test = train_test_split(images_meanstd, \n",
    "                                                                                       X, \n",
    "                                                                                       y, \n",
    "                                                                                       test_size=test_size,\n",
    "                                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Priit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Priit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10794 samples, validate on 1200 samples\n",
      "Epoch 1/10\n",
      "10794/10794 [==============================] - ETA: 22:30 - loss: 1.6541 - acc: 0.11 - ETA: 22:50 - loss: 1.6318 - acc: 0.19 - ETA: 20:26 - loss: 1.6116 - acc: 0.21 - ETA: 18:32 - loss: 1.6319 - acc: 0.22 - ETA: 17:02 - loss: 1.6187 - acc: 0.25 - ETA: 15:41 - loss: 1.5946 - acc: 0.26 - ETA: 1:35:40 - loss: 1.5793 - acc: 0.27 - ETA: 1:19:55 - loss: 1.5770 - acc: 0.27 - ETA: 1:07:39 - loss: 1.5754 - acc: 0.27 - ETA: 57:33 - loss: 1.5676 - acc: 0.2830 - ETA: 48:58 - loss: 1.5621 - acc: 0.28 - ETA: 41:36 - loss: 1.5548 - acc: 0.28 - ETA: 35:10 - loss: 1.5484 - acc: 0.29 - ETA: 29:29 - loss: 1.5420 - acc: 0.29 - ETA: 24:19 - loss: 1.5359 - acc: 0.29 - ETA: 19:35 - loss: 1.5301 - acc: 0.29 - ETA: 15:15 - loss: 1.5249 - acc: 0.29 - ETA: 11:09 - loss: 1.5188 - acc: 0.29 - ETA: 7:19 - loss: 1.5144 - acc: 0.2975 - ETA: 3:42 - loss: 1.5112 - acc: 0.299 - ETA: 16s - loss: 1.5084 - acc: 0.299 - 4423s 410ms/step - loss: 1.5080 - acc: 0.2993 - val_loss: 1.4454 - val_acc: 0.3450\n",
      "Epoch 2/10\n",
      "10794/10794 [==============================] - ETA: 32:07 - loss: 1.4796 - acc: 0.32 - ETA: 30:37 - loss: 1.4417 - acc: 0.33 - ETA: 29:08 - loss: 1.4414 - acc: 0.33 - ETA: 3:19:02 - loss: 1.4315 - acc: 0.35 - ETA: 2:33:10 - loss: 1.4455 - acc: 0.34 - ETA: 2:02:05 - loss: 1.4403 - acc: 0.33 - ETA: 1:39:35 - loss: 1.4355 - acc: 0.34 - ETA: 1:22:30 - loss: 1.4308 - acc: 0.34 - ETA: 1:09:00 - loss: 1.4302 - acc: 0.34 - ETA: 58:03 - loss: 1.4302 - acc: 0.3400 - ETA: 48:53 - loss: 1.4312 - acc: 0.33 - ETA: 41:05 - loss: 1.4273 - acc: 0.33 - ETA: 34:20 - loss: 1.4252 - acc: 0.34 - ETA: 28:25 - loss: 1.4239 - acc: 0.34 - ETA: 23:10 - loss: 1.4244 - acc: 0.34 - ETA: 18:27 - loss: 1.4250 - acc: 0.34 - ETA: 14:11 - loss: 1.4239 - acc: 0.34 - ETA: 10:16 - loss: 1.4232 - acc: 0.34 - ETA: 6:40 - loss: 1.4230 - acc: 0.3444 - ETA: 3:21 - loss: 1.4210 - acc: 0.345 - ETA: 14s - loss: 1.4193 - acc: 0.347 - 3889s 360ms/step - loss: 1.4354 - acc: 0.3469 - val_loss: 1.4214 - val_acc: 0.3708\n",
      "Epoch 3/10\n",
      "10794/10794 [==============================] - ETA: 18:23 - loss: 1.4044 - acc: 0.36 - ETA: 17:22 - loss: 1.4070 - acc: 0.35 - ETA: 16:22 - loss: 1.4187 - acc: 0.35 - ETA: 15:27 - loss: 1.4139 - acc: 0.35 - ETA: 14:30 - loss: 1.4115 - acc: 0.35 - ETA: 13:37 - loss: 1.4131 - acc: 0.35 - ETA: 12:42 - loss: 1.4110 - acc: 0.35 - ETA: 11:48 - loss: 1.4184 - acc: 0.35 - ETA: 10:53 - loss: 1.4174 - acc: 0.35 - ETA: 9:59 - loss: 1.4160 - acc: 0.3547 - ETA: 9:04 - loss: 1.4159 - acc: 0.354 - ETA: 8:10 - loss: 1.4131 - acc: 0.358 - ETA: 7:17 - loss: 1.4122 - acc: 0.361 - ETA: 6:23 - loss: 1.4087 - acc: 0.364 - ETA: 5:29 - loss: 1.4060 - acc: 0.364 - ETA: 4:34 - loss: 1.4074 - acc: 0.363 - ETA: 3:40 - loss: 1.4057 - acc: 0.363 - ETA: 2:46 - loss: 1.4075 - acc: 0.360 - ETA: 1:52 - loss: 1.4066 - acc: 0.362 - ETA: 58s - loss: 1.4073 - acc: 0.362 - ETA: 4s - loss: 1.4080 - acc: 0.3616 - 1255s 116ms/step - loss: 1.4081 - acc: 0.3615 - val_loss: 1.4151 - val_acc: 0.3500\n",
      "Epoch 4/10\n",
      "10794/10794 [==============================] - ETA: 18:04 - loss: 1.3772 - acc: 0.39 - ETA: 17:09 - loss: 1.3791 - acc: 0.38 - ETA: 16:17 - loss: 1.3998 - acc: 0.35 - ETA: 15:20 - loss: 1.3854 - acc: 0.37 - ETA: 14:27 - loss: 1.3854 - acc: 0.37 - ETA: 13:32 - loss: 1.3976 - acc: 0.36 - ETA: 12:39 - loss: 1.3964 - acc: 0.37 - ETA: 11:45 - loss: 1.3930 - acc: 0.37 - ETA: 10:52 - loss: 1.3925 - acc: 0.37 - ETA: 9:57 - loss: 1.3947 - acc: 0.3768 - ETA: 9:03 - loss: 1.3938 - acc: 0.375 - ETA: 8:09 - loss: 1.3957 - acc: 0.373 - ETA: 7:15 - loss: 1.3930 - acc: 0.374 - ETA: 6:22 - loss: 1.3906 - acc: 0.375 - ETA: 5:28 - loss: 1.3902 - acc: 0.375 - ETA: 4:34 - loss: 1.3890 - acc: 0.377 - ETA: 3:40 - loss: 1.3872 - acc: 0.378 - ETA: 2:46 - loss: 1.3883 - acc: 0.377 - ETA: 1:52 - loss: 1.3889 - acc: 0.376 - ETA: 58s - loss: 1.3887 - acc: 0.376 - ETA: 4s - loss: 1.3886 - acc: 0.3768 - 1270s 118ms/step - loss: 1.3877 - acc: 0.3774 - val_loss: 1.4095 - val_acc: 0.3575\n",
      "Epoch 5/10\n",
      "10794/10794 [==============================] - ETA: 20:39 - loss: 1.3710 - acc: 0.38 - ETA: 19:32 - loss: 1.3916 - acc: 0.39 - ETA: 18:26 - loss: 1.3839 - acc: 0.38 - ETA: 17:16 - loss: 1.3772 - acc: 0.38 - ETA: 16:17 - loss: 1.3690 - acc: 0.38 - ETA: 15:10 - loss: 1.3710 - acc: 0.39 - ETA: 14:15 - loss: 1.3680 - acc: 0.38 - ETA: 13:13 - loss: 1.3671 - acc: 0.38 - ETA: 12:17 - loss: 1.3695 - acc: 0.38 - ETA: 11:20 - loss: 1.3726 - acc: 0.38 - ETA: 10:21 - loss: 1.3726 - acc: 0.38 - ETA: 9:19 - loss: 1.3762 - acc: 0.3843 - ETA: 8:21 - loss: 1.3756 - acc: 0.384 - ETA: 7:24 - loss: 1.3752 - acc: 0.383 - ETA: 6:27 - loss: 1.3742 - acc: 0.385 - ETA: 5:29 - loss: 1.3730 - acc: 0.385 - ETA: 4:26 - loss: 1.3705 - acc: 0.386 - ETA: 3:23 - loss: 1.3692 - acc: 0.386 - ETA: 2:18 - loss: 1.3674 - acc: 0.388 - ETA: 1:12 - loss: 1.3678 - acc: 0.389 - ETA: 5s - loss: 1.3666 - acc: 0.3887  - 1558s 144ms/step - loss: 1.3682 - acc: 0.3882 - val_loss: 1.4085 - val_acc: 0.3617\n",
      "Epoch 6/10\n",
      "10794/10794 [==============================] - ETA: 21:07 - loss: 1.3700 - acc: 0.38 - ETA: 19:45 - loss: 1.3546 - acc: 0.39 - ETA: 18:59 - loss: 1.3586 - acc: 0.38 - ETA: 17:54 - loss: 1.3445 - acc: 0.39 - ETA: 17:01 - loss: 1.3400 - acc: 0.39 - ETA: 15:53 - loss: 1.3384 - acc: 0.39 - ETA: 14:44 - loss: 1.3394 - acc: 0.39 - ETA: 13:40 - loss: 1.3418 - acc: 0.39 - ETA: 12:40 - loss: 1.3486 - acc: 0.39 - ETA: 11:34 - loss: 1.3513 - acc: 0.38 - ETA: 10:28 - loss: 1.3529 - acc: 0.38 - ETA: 9:24 - loss: 1.3527 - acc: 0.3892 - ETA: 8:23 - loss: 1.3520 - acc: 0.388 - ETA: 7:25 - loss: 1.3532 - acc: 0.389 - ETA: 6:22 - loss: 1.3532 - acc: 0.391 - ETA: 5:18 - loss: 1.3534 - acc: 0.391 - ETA: 4:15 - loss: 1.3510 - acc: 0.393 - ETA: 3:13 - loss: 1.3513 - acc: 0.393 - ETA: 2:12 - loss: 1.3509 - acc: 0.394 - ETA: 1:09 - loss: 1.3512 - acc: 0.394 - ETA: 5s - loss: 1.3475 - acc: 0.3975  - 1501s 139ms/step - loss: 1.3482 - acc: 0.3972 - val_loss: 1.4064 - val_acc: 0.3592\n",
      "Epoch 7/10\n",
      "10794/10794 [==============================] - ETA: 23:28 - loss: 1.3172 - acc: 0.39 - ETA: 22:11 - loss: 1.3147 - acc: 0.40 - ETA: 21:43 - loss: 1.3039 - acc: 0.41 - ETA: 19:50 - loss: 1.3302 - acc: 0.40 - ETA: 18:27 - loss: 1.3280 - acc: 0.41 - ETA: 17:05 - loss: 1.3278 - acc: 0.41 - ETA: 15:51 - loss: 1.3258 - acc: 0.41 - ETA: 14:41 - loss: 1.3275 - acc: 0.41 - ETA: 13:28 - loss: 1.3275 - acc: 0.41 - ETA: 12:16 - loss: 1.3260 - acc: 0.41 - ETA: 11:08 - loss: 1.3296 - acc: 0.40 - ETA: 10:00 - loss: 1.3311 - acc: 0.40 - ETA: 8:57 - loss: 1.3305 - acc: 0.4064 - ETA: 7:49 - loss: 1.3327 - acc: 0.406 - ETA: 6:41 - loss: 1.3333 - acc: 0.405 - ETA: 5:35 - loss: 1.3321 - acc: 0.406 - ETA: 4:27 - loss: 1.3323 - acc: 0.407 - ETA: 3:21 - loss: 1.3331 - acc: 0.407 - ETA: 2:17 - loss: 1.3339 - acc: 0.407 - ETA: 1:11 - loss: 1.3344 - acc: 0.407 - ETA: 5s - loss: 1.3338 - acc: 0.4075  - 1523s 141ms/step - loss: 1.3369 - acc: 0.4072 - val_loss: 1.4026 - val_acc: 0.3758\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10794/10794 [==============================] - ETA: 24:06 - loss: 1.3071 - acc: 0.43 - ETA: 21:39 - loss: 1.3107 - acc: 0.43 - ETA: 20:14 - loss: 1.3193 - acc: 0.43 - ETA: 18:57 - loss: 1.3067 - acc: 0.43 - ETA: 17:45 - loss: 1.3083 - acc: 0.43 - ETA: 17:03 - loss: 1.3092 - acc: 0.43 - ETA: 16:18 - loss: 1.3092 - acc: 0.42 - ETA: 15:25 - loss: 1.3102 - acc: 0.43 - ETA: 14:14 - loss: 1.3098 - acc: 0.43 - ETA: 12:59 - loss: 1.3095 - acc: 0.43 - ETA: 11:48 - loss: 1.3110 - acc: 0.43 - ETA: 10:35 - loss: 1.3091 - acc: 0.43 - ETA: 9:19 - loss: 1.3059 - acc: 0.4330 - ETA: 8:03 - loss: 1.3057 - acc: 0.430 - ETA: 6:50 - loss: 1.3071 - acc: 0.428 - ETA: 5:39 - loss: 1.3099 - acc: 0.428 - ETA: 4:30 - loss: 1.3095 - acc: 0.429 - ETA: 3:22 - loss: 1.3084 - acc: 0.430 - ETA: 2:16 - loss: 1.3081 - acc: 0.431 - ETA: 1:11 - loss: 1.3106 - acc: 0.427 - ETA: 5s - loss: 1.3108 - acc: 0.4281  - 3592s 333ms/step - loss: 1.3107 - acc: 0.4285 - val_loss: 1.4366 - val_acc: 0.3575\n",
      "Epoch 9/10\n",
      "10794/10794 [==============================] - ETA: 34:29 - loss: 1.3265 - acc: 0.40 - ETA: 33:06 - loss: 1.3114 - acc: 0.41 - ETA: 31:26 - loss: 1.3066 - acc: 0.41 - ETA: 29:49 - loss: 1.2960 - acc: 0.43 - ETA: 27:26 - loss: 1.3087 - acc: 0.42 - ETA: 25:21 - loss: 1.3070 - acc: 0.42 - ETA: 23:23 - loss: 1.3091 - acc: 0.42 - ETA: 21:40 - loss: 1.3076 - acc: 0.41 - ETA: 20:00 - loss: 1.3063 - acc: 0.41 - ETA: 18:18 - loss: 1.3090 - acc: 0.41 - ETA: 16:40 - loss: 1.3046 - acc: 0.42 - ETA: 15:00 - loss: 1.3038 - acc: 0.42 - ETA: 13:15 - loss: 1.3030 - acc: 0.42 - ETA: 11:32 - loss: 1.3039 - acc: 0.42 - ETA: 9:52 - loss: 1.3044 - acc: 0.4225 - ETA: 8:15 - loss: 1.3055 - acc: 0.423 - ETA: 6:37 - loss: 1.3046 - acc: 0.425 - ETA: 4:59 - loss: 1.3038 - acc: 0.426 - ETA: 3:21 - loss: 1.3033 - acc: 0.427 - ETA: 1:44 - loss: 1.3035 - acc: 0.427 - ETA: 8s - loss: 1.3034 - acc: 0.4284  - 2299s 213ms/step - loss: 1.3061 - acc: 0.4275 - val_loss: 1.4149 - val_acc: 0.3775\n",
      "Epoch 10/10\n",
      "10794/10794 [==============================] - ETA: 31:34 - loss: 1.2723 - acc: 0.46 - ETA: 30:19 - loss: 1.2757 - acc: 0.44 - ETA: 29:00 - loss: 1.2863 - acc: 0.44 - ETA: 27:28 - loss: 1.2887 - acc: 0.44 - ETA: 26:17 - loss: 1.2779 - acc: 0.44 - ETA: 24:38 - loss: 1.2753 - acc: 0.45 - ETA: 23:02 - loss: 1.2773 - acc: 0.45 - ETA: 21:20 - loss: 1.2760 - acc: 0.45 - ETA: 19:35 - loss: 1.2738 - acc: 0.45 - ETA: 17:50 - loss: 1.2693 - acc: 0.45 - ETA: 16:07 - loss: 1.2678 - acc: 0.45 - ETA: 14:25 - loss: 1.2646 - acc: 0.46 - ETA: 12:46 - loss: 1.2646 - acc: 0.45 - ETA: 11:09 - loss: 1.2638 - acc: 0.45 - ETA: 9:35 - loss: 1.2645 - acc: 0.4574 - ETA: 7:59 - loss: 1.2657 - acc: 0.457 - ETA: 6:25 - loss: 1.2705 - acc: 0.454 - ETA: 4:51 - loss: 1.2708 - acc: 0.453 - ETA: 3:19 - loss: 1.2695 - acc: 0.452 - ETA: 1:44 - loss: 1.2736 - acc: 0.449 - ETA: 7s - loss: 1.2729 - acc: 0.4501  - 2242s 208ms/step - loss: 1.2736 - acc: 0.4495 - val_loss: 1.4132 - val_acc: 0.3692\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49618986/neural-network-in-keras-with-two-different-input-types-images-and-values\n",
    "# https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/\n",
    "\n",
    "transfer = Xception(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
    "\n",
    "# Freeze Xception\n",
    "for layer in transfer.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Inputs\n",
    "image_input = Input(shape=(height, width, 3))\n",
    "aux_input = Input(shape=(len(list(X_train_else)),))\n",
    "\n",
    "# Images:\n",
    "transfer = transfer(image_input)\n",
    "transfer = Dense(150, activation='relu')(transfer)\n",
    "flatten = Flatten()(transfer)\n",
    "\n",
    "# Aux input:\n",
    "x = Dense(150, activation='relu')(aux_input)\n",
    "x = Dense(250, activation='relu')(x)\n",
    "x = Dense(350, activation='relu')(x)\n",
    "\n",
    "# Merged:\n",
    "merge = concatenate([flatten, x])\n",
    "x = Dense(500)(merge)\n",
    "x = Dense(450, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "h = Dense(5)(x)\n",
    "\n",
    "# Predictions:\n",
    "predictions = Activation('softmax')(h)\n",
    "\n",
    "def kappa(y_true, y_pred):\n",
    "    y_pred = map(lambda x: np.argmax(x), y_pred) \n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "model = Model(inputs=[image_input, aux_input], outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit([X_train_img, X_train_else], \n",
    "                    keras.utils.to_categorical(y_train),\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=10, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_pred = [np.argmax(pred) for pred in model.predict([X_train_img, X_train_else])]\n",
    "test_predictions = [np.argmax(pred) for pred in model.predict([X_test_img, X_test_else])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa on train: 0.377\n",
      "Accuracy on train: 0.447\n",
      "________________\n",
      "Kappa on test: 0.2542\n",
      "Accuracy on test: 0.3525\n"
     ]
    }
   ],
   "source": [
    "print(\"Kappa on train: {}\".format(round(cohen_kappa_score(y_train, train_pred, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on train: {}\".format(round(accuracy_score(y_train, train_pred), 4)))\n",
    "print(\"________________\")\n",
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_test, test_predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_test, test_predictions), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "model.save('test_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PetFinderNN)",
   "language": "python",
   "name": "pycharm-b185692d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
