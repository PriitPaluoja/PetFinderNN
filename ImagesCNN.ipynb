{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import (Conv2D, Flatten, Lambda, Dense, concatenate,\n",
    "                          Dropout, Input)\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "data_image = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisnärvivõrgud\\\\data\\\\train_images\"\n",
    "data_dir = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisnärvivõrgud\\\\data\"\n",
    "\n",
    "label_column = \"AdoptionSpeed\"\n",
    "\n",
    "LIMIT = 30\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), sep=',', nrows=LIMIT if LIMIT != -1 else None)\n",
    "pet_ids = train[\"PetID\"]\n",
    "\n",
    "selected_columns = [\"Type\",\n",
    "                    \"Gender\",\n",
    "                    \"Color1\",\n",
    "                    \"Color2\",\n",
    "                    \"Color3\",\n",
    "                    \"MaturitySize\",\n",
    "                    \"FurLength\",\n",
    "                    \"Vaccinated\",\n",
    "                    \"Dewormed\",\n",
    "                    \"Sterilized\",\n",
    "                    \"Health\",\n",
    "                    \"State\",\n",
    "                    \"MaturitySize\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = train[label_column]\n",
    "\n",
    "# One-Hot-encode\n",
    "# X = pd.get_dummies(train[selected_columns], columns=selected_columns)\n",
    "\n",
    "# Normalize:\n",
    "# to_normalize = [\"Age\", \"Fee\", \"Quantity\"]\n",
    "# for to_norm in to_normalize:\n",
    "#     X[to_norm] = (train[to_norm] - train[to_norm].mean()) / train[to_norm].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 31.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "height, width = 320, 320\n",
    "image_paths = [os.path.join(data_dir, data_image, pet_id + \"-1.jpg\") for pet_id in pet_ids][:LIMIT]\n",
    "\n",
    "images = []\n",
    "\n",
    "for path in tqdm(image_paths):\n",
    "    if os.path.isfile(path):\n",
    "        image = Image.open(path).convert(\"RGB\") \n",
    "        image.load()\n",
    "        image = np.asarray(image, dtype=\"int32\" )\n",
    "        image = resize(image, (height, width), anti_aliasing=True, mode='constant')\n",
    "    else:\n",
    "        image = np.random.rand(height, width, 3) * 255\n",
    "        \n",
    "    images.append(image)\n",
    "    \n",
    "images = np.array(images)\n",
    "\n",
    "# Standardize:\n",
    "mean = np.mean(images)\n",
    "std = np.std(images)\n",
    "\n",
    "images_meanstd = (images - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_meanstd, y, test_size=test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19 samples, validate on 5 samples\n",
      "Epoch 1/5\n",
      "19/19 [==============================] - 7s 343ms/step - loss: 1.9462 - acc: 0.1053 - val_loss: 9.6709 - val_acc: 0.4000\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 2s 129ms/step - loss: 8.4832 - acc: 0.4737 - val_loss: 9.6709 - val_acc: 0.4000\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 3s 135ms/step - loss: 8.4832 - acc: 0.4737 - val_loss: 9.6709 - val_acc: 0.4000\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 2s 131ms/step - loss: 8.4832 - acc: 0.4737 - val_loss: 9.6709 - val_acc: 0.4000\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 3s 133ms/step - loss: 8.4832 - acc: 0.4737 - val_loss: 9.6709 - val_acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(height, width, 3))\n",
    "h = Conv2D(32, (14, 14), strides=(2, 2))(inputs)\n",
    "h = Conv2D(32, (7, 7), strides=(2, 2))(inputs)\n",
    "h = Activation('relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(100)(h)\n",
    "h = Dense(100)(h)\n",
    "h = Dense(5)(h)\n",
    "predictions = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    keras.utils.to_categorical(y_train),\n",
    "                    batch_size=64, \n",
    "                    epochs=5, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2]\n",
      "Kappa on train: 0.45\n",
      "Accuracy on train: 0.4583\n",
      "________________\n",
      "Kappa on test: 0.0\n",
      "Accuracy on test: 0.3333\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = [np.argmax(pred) for pred in test_predictions]\n",
    "print(test_predictions)\n",
    "\n",
    "train_pred = [np.argmax(pred) for pred in model.predict(X_train)]\n",
    "\n",
    "print(\"Kappa on train: {}\".format(round(cohen_kappa_score(y_train, train_pred, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on train: {}\".format(round(accuracy_score(y_train, train_pred), 4)))\n",
    "print(\"________________\")\n",
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_test, test_predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_test, test_predictions), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/49618986/neural-network-in-keras-with-two-different-input-types-images-and-values\n",
    "# TODO: read images in\n",
    "# TODO: read features in\n",
    "image = np.random.rand(10, 66, 200, 3)\n",
    "feature = np.random.rand(10, 3)  # feature vector\n",
    "y = np.random.normal(0, 1, (10, 1))\n",
    "\n",
    "image_input = Input(shape=(66, 200, 3))\n",
    "aux_input = Input(shape=(3,))\n",
    "\n",
    "lamb = Lambda(lambda x: x / 127.5 - 1.0, input_shape=(66, 200, 3))(image_input)\n",
    "cov1 = Conv2D(24, 5, 5, activation='elu', subsample=(2, 2))(lamb)\n",
    "cov2 = Conv2D(36, 5, 5, activation='elu', subsample=(2, 2))(cov1)\n",
    "cov3 = Conv2D(48, 5, 5, activation='elu', subsample=(2, 2))(cov2)\n",
    "cov4 = Conv2D(64, 3, 3, activation='elu')(cov3)\n",
    "cov5 = Conv2D(64, 3, 3, activation='elu')(cov4)\n",
    "dropout = Dropout(0.5)(cov5)\n",
    "flatten = Flatten()(dropout)\n",
    "\n",
    "# Here we add in the feature vectors\n",
    "merge = concatenate([flatten, aux_input])\n",
    "\n",
    "d1 = Dense(100, activation='elu')(merge)\n",
    "d2 = Dense(50, activation='elu')(d1)\n",
    "d3 = Dense(10, activation='elu')(d2)\n",
    "out = Dense(1)(d3)\n",
    "\n",
    "model = Model(inputs=[image_input, aux_input], outputs=[out])\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.fit([image, feature], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PetFinderNN)",
   "language": "python",
   "name": "pycharm-b185692d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
