{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PetFinder.my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import keras.utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.applications import Xception\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Activation, Flatten, Dense\n",
    "from keras.layers import (concatenate)\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisnärvivõrgud\\\\data\"\n",
    "\n",
    "train_image = os.path.join(data_dir, \"train_images\")\n",
    "test_image = os.path.join(data_dir, \"test_images\")\n",
    "\n",
    "label_column = \"AdoptionSpeed\"\n",
    "\n",
    "BATCH_SIZE, test_size = 512, 0.2\n",
    "\n",
    "height, width = 100, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "### Helper functions for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def read_csv_kaggle(path, is_train):\n",
    "    train = pd.read_csv(path, sep=',')\n",
    "    pet_ids = train[\"PetID\"]\n",
    "\n",
    "    selected_columns = [\"Type\",\n",
    "                        \"Gender\",\n",
    "                        \"Color1\",\n",
    "                        \"Color2\",\n",
    "                        \"Color3\",\n",
    "                        \"MaturitySize\",\n",
    "                        \"FurLength\",\n",
    "                        \"Vaccinated\",\n",
    "                        \"Dewormed\",\n",
    "                        \"Sterilized\",\n",
    "                        \"Health\",\n",
    "                        #\"State\",\n",
    "                        \"MaturitySize\"]\n",
    "    \n",
    "    y = train[label_column] if is_train else None\n",
    "    \n",
    "    # One-Hot-encode\n",
    "    X = pd.get_dummies(train[selected_columns], columns=selected_columns)\n",
    "\n",
    "    # Normalize:\n",
    "    to_normalize = [\"Age\", \"Fee\", \"Quantity\"]\n",
    "    for to_norm in to_normalize:\n",
    "         X[to_norm] = (train[to_norm] - train[to_norm].mean()) / train[to_norm].std()\n",
    "    \n",
    "    return X, y, pet_ids\n",
    "\n",
    "def read_images(image_paths):\n",
    "    def random_image():\n",
    "        return np.random.rand(height, width, 3) * 255\n",
    "    \n",
    "    def read_image(path):\n",
    "        img = np.asarray(Image.open(path).convert(\"RGB\"), dtype=\"int32\" )\n",
    "        return resize(img, (height, width), anti_aliasing=True, mode='constant')    \n",
    "\n",
    "    return np.array([read_image(path) if os.path.isfile(path) else random_image() for path in tqdm(image_paths)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "X, y, pet_ids = read_csv_kaggle(os.path.join(data_dir, \"train.csv\"), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "f_im_name = \"images.binary\"\n",
    "\n",
    "if not os.path.isfile(f_im_name):\n",
    "    images = read_images([os.path.join(train_image, pet_id + \"-1.jpg\") for pet_id in pet_ids])\n",
    "    \n",
    "    # Standardize:\n",
    "    mean, std = np.mean(images), np.std(images)\n",
    "    images_meanstd = (images - mean)/std\n",
    "    \n",
    "    with open(f_im_name, 'wb') as handle_1, open(\"mnstd\", 'wb') as handle_2:\n",
    "        pickle.dump(images_meanstd, handle_1, protocol=pickle.HIGHEST_PROTOCOL)        \n",
    "        pickle.dump((mean, std), handle_2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f_im_name, 'rb') as handle_1, open(\"mnstd\", 'rb') as handle_2:\n",
    "        images_meanstd = pickle.load(handle_1)\n",
    "        temp = pickle.load(handle_2)\n",
    "        mean, std = temp[0], temp[1]\n",
    "                \n",
    "print(images_meanstd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split traint/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, X_train_else, X_test_else, y_train, y_test = train_test_split(images_meanstd, \n",
    "                                                                                       X, \n",
    "                                                                                       y, \n",
    "                                                                                       test_size=test_size,\n",
    "                                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create & train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=65, max_depth=15)\n",
    "rf.fit(X_train_else, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/49618986/neural-network-in-keras-with-two-different-input-types-images-and-values\n",
    "# https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/\n",
    "\n",
    "transfer = Xception(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
    "\n",
    "# Freeze Xception\n",
    "#for layer in transfer.layers[:-9]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Inputs\n",
    "image_input = Input(shape=(height, width, 3))\n",
    "aux_input = Input(shape=(len(list(X_train_else)),))\n",
    "\n",
    "# Images:\n",
    "transfer = transfer(image_input)\n",
    "transfer = Dense(150, activation='relu')(transfer)\n",
    "flatten = Flatten()(transfer)\n",
    "\n",
    "# Aux input:\n",
    "x = Dense(150, activation='relu')(aux_input)\n",
    "\n",
    "# Merged:\n",
    "merge = concatenate([flatten, x])\n",
    "x = Dense(500)(merge)\n",
    "h = Dense(5)(x)\n",
    "\n",
    "# Predictions:\n",
    "predictions = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=[image_input, aux_input], outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit([X_train_img, X_train_else], \n",
    "                    keras.utils.to_categorical(y_train),\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=4, \n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[ModelCheckpoint('test_model.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models\n",
    "\n",
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_pred = [np.argmax(pred) for pred in model.predict([X_train_img, X_train_else])]\n",
    "test_predictions = [np.argmax(pred) for pred in model.predict([X_test_img, X_test_else])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(\"Kappa on train: {}\".format(round(cohen_kappa_score(y_train, train_pred, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on train: {}\".format(round(accuracy_score(y_train, train_pred), 4)))\n",
    "print(\"________________\")\n",
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_test, test_predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_test, test_predictions), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_pred = [pred for pred in rf.predict(X_train_else)]\n",
    "test_predictions = [pred for pred in rf.predict(X_test_else)]\n",
    "\n",
    "print(\"Kappa on train: {}\".format(round(cohen_kappa_score(y_train, train_pred, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on train: {}\".format(round(accuracy_score(y_train, train_pred), 4)))\n",
    "print(\"________________\")\n",
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_test, test_predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_test, test_predictions), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "test, _, test_pet_ids = read_csv_kaggle(os.path.join(data_dir, \"test.csv\"), False)\n",
    "test_images = read_images([os.path.join(test_image, pet_id + \"-1.jpg\") for pet_id in test_pet_ids])\n",
    "test_images_std = (test_images - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "loaded = load_model('test_model.h5')\n",
    "test_pred = loaded.predict([test_images_std, test])\n",
    "test_pred_label = [np.argmax(pred) for pred in test_pred]\n",
    "pd.DataFrame({'PetID': test_pet_ids, 'AdoptionSpeed': test_pred_label}).to_csv('neural.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'PetID': test_pet_ids, 'AdoptionSpeed': rf.predict(test)}).to_csv('baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PetFinderNN)",
   "language": "python",
   "name": "pycharm-b185692d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}