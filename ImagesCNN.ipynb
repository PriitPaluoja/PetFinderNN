{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import keras.utils\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import (Conv2D, Flatten, Lambda, Dense, concatenate,\n",
    "                          Dropout, Input)\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Activation, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "data_image = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisn채rviv천rgud\\\\data\\\\train_images\"\n",
    "data_dir = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisn채rviv천rgud\\\\data\"\n",
    "\n",
    "label_column = \"AdoptionSpeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), sep=',')\n",
    "pet_ids = train[\"PetID\"]\n",
    "\n",
    "selected_columns = [\"Type\",\n",
    "                    \"Gender\",\n",
    "                    \"Color1\",\n",
    "                    \"Color2\",\n",
    "                    \"Color3\",\n",
    "                    \"MaturitySize\",\n",
    "                    \"FurLength\",\n",
    "                    \"Vaccinated\",\n",
    "                    \"Dewormed\",\n",
    "                    \"Sterilized\",\n",
    "                    \"Health\",\n",
    "                    \"State\",\n",
    "                    \"MaturitySize\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = train[label_column]\n",
    "\n",
    "# One-Hot-encode\n",
    "X = pd.get_dummies(train[selected_columns], columns=selected_columns)\n",
    "\n",
    "# Normalize:\n",
    "to_normalize = [\"Age\", \"Fee\", \"Quantity\"]\n",
    "for to_norm in to_normalize:\n",
    "    X[to_norm] = (train[to_norm] - train[to_norm].mean()) / train[to_norm].std()\n",
    "\n",
    "X = train.assign(paths=[os.path.join(data_dir, data_image, pet_id + \"-1.jpg\") for pet_id in pet_ids])\n",
    "\n",
    "# Convert labels to str\n",
    "X[label_column] = X[label_column].astype(str)\n",
    "\n",
    "X_test = X.iloc[:400, :]\n",
    "X_train = X.iloc[400:, :]\n",
    "X_train = X_train.reset_index()\n",
    "X_test = X_test.reset_index()\n",
    "#X[\"paths\"]\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14267 images belonging to 5 classes.\n",
      "Found 385 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "# TODO: fill\n",
    "data_gen_args = dict()\n",
    "\n",
    "height, width = 320, 320\n",
    "batch = 8\n",
    "\n",
    "train_imggen = ImageDataGenerator(data_gen_args) #rescale=1./255, rotation_range=30, horizontal_flip=True)\n",
    "\n",
    "train_loader = train_imggen.flow_from_dataframe(X_train, x_col='paths',\n",
    "                                                y_col=label_column,                                         \n",
    "                                                target_size=(height, width), \n",
    "                                                class_mode='categorical', \n",
    "                                                validation_split=0.2,\n",
    "                                                batch_size=batch)\n",
    "\n",
    "test_imggen = ImageDataGenerator(data_gen_args)\n",
    "test_loader = train_imggen.flow_from_dataframe(X_test, \n",
    "                                               x_col='paths',\n",
    "                                               y_col=label_column,                                         \n",
    "                                               target_size=(height, width), \n",
    "                                               class_mode='categorical', \n",
    "                                               batch_size=batch)\n",
    "\n",
    "#train_imggen.fit()\n",
    "#test_imggen.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Priit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Priit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - ETA: 12s - loss: 12.0890 - acc: 0.250 - ETA: 7s - loss: 12.0888 - acc: 0.250 - ETA: 5s - loss: 12.7603 - acc: 0.20 - ETA: 3s - loss: 12.0887 - acc: 0.25 - ETA: 3s - loss: 12.4916 - acc: 0.22 - ETA: 2s - loss: 12.0887 - acc: 0.25 - ETA: 1s - loss: 12.0886 - acc: 0.25 - ETA: 1s - loss: 12.0886 - acc: 0.25 - ETA: 0s - loss: 11.8648 - acc: 0.26 - 5s 518ms/step - loss: 11.8871 - acc: 0.2625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164341e5ba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(height, width, 3))\n",
    "h = Conv2D(32, (7, 7), strides=(2, 2))(inputs)\n",
    "h = Activation('relu')(h)\n",
    "h = Flatten()(h)\n",
    "h = Dense(5)(h)\n",
    "predictions = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_loader, epochs=1, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "#pred = model.predict_generator(test_loader, steps=len(X_test.index), verbose=1)\n",
    "predictions = []\n",
    "y_true = []\n",
    "\n",
    "#for x, y in tqdm(test_loader):\n",
    "    #y_true.append(np.argmax(y))\n",
    "    #predictions.append(np.argmax(model.predict(x)))\n",
    "\n",
    "batch_index = 0\n",
    "while batch_index <= test_loader.batch_index:\n",
    "    data = test_loader.next()\n",
    "    #data_list.append(data[0])\n",
    "    batch_index = batch_index + 1\n",
    "    print(batch_index)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_true, predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_true, predictions), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/49618986/neural-network-in-keras-with-two-different-input-types-images-and-values\n",
    "# TODO: read images in\n",
    "# TODO: read features in\n",
    "image = np.random.rand(10, 66, 200, 3)\n",
    "feature = np.random.rand(10, 3)  # feature vector\n",
    "y = np.random.normal(0, 1, (10, 1))\n",
    "\n",
    "image_input = Input(shape=(66, 200, 3))\n",
    "aux_input = Input(shape=(3,))\n",
    "\n",
    "lamb = Lambda(lambda x: x / 127.5 - 1.0, input_shape=(66, 200, 3))(image_input)\n",
    "cov1 = Conv2D(24, 5, 5, activation='elu', subsample=(2, 2))(lamb)\n",
    "cov2 = Conv2D(36, 5, 5, activation='elu', subsample=(2, 2))(cov1)\n",
    "cov3 = Conv2D(48, 5, 5, activation='elu', subsample=(2, 2))(cov2)\n",
    "cov4 = Conv2D(64, 3, 3, activation='elu')(cov3)\n",
    "cov5 = Conv2D(64, 3, 3, activation='elu')(cov4)\n",
    "dropout = Dropout(0.5)(cov5)\n",
    "flatten = Flatten()(dropout)\n",
    "\n",
    "# Here we add in the feature vectors\n",
    "merge = concatenate([flatten, aux_input])\n",
    "\n",
    "d1 = Dense(100, activation='elu')(merge)\n",
    "d2 = Dense(50, activation='elu')(d1)\n",
    "d3 = Dense(10, activation='elu')(d2)\n",
    "out = Dense(1)(d3)\n",
    "\n",
    "model = Model(inputs=[image_input, aux_input], outputs=[out])\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.fit([image, feature], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PetFinderNN)",
   "language": "python",
   "name": "pycharm-b185692d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
