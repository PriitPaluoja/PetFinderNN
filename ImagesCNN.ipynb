{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras.applications import Xception\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Activation, Flatten, Dense\n",
    "from keras.layers import (concatenate)\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\Priit\\\\Dropbox\\\\Informaatika\\\\Magister\\\\Tehisnärvivõrgud\\\\data\"\n",
    "\n",
    "train_image = os.path.join(data_dir, \"train_images\")\n",
    "test_image = os.path.join(data_dir, \"test_images\")\n",
    "\n",
    "label_column = \"AdoptionSpeed\"\n",
    "\n",
    "BATCH_SIZE, test_size = 512, 0.2\n",
    "\n",
    "height, width = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def read_csv_kaggle(path, is_train):\n",
    "    train = pd.read_csv(path, sep=',')\n",
    "    pet_ids = train[\"PetID\"]\n",
    "\n",
    "    selected_columns = [\"Type\",\n",
    "                        \"Gender\",\n",
    "                        \"Color1\",\n",
    "                        \"Color2\",\n",
    "                        \"Color3\",\n",
    "                        \"MaturitySize\",\n",
    "                        \"FurLength\",\n",
    "                        \"Vaccinated\",\n",
    "                        \"Dewormed\",\n",
    "                        \"Sterilized\",\n",
    "                        \"Health\",\n",
    "                        #\"State\",\n",
    "                        \"MaturitySize\"]\n",
    "    \n",
    "    y = train[label_column] if is_train else None\n",
    "    \n",
    "    # One-Hot-encode\n",
    "    X = pd.get_dummies(train[selected_columns], columns=selected_columns)\n",
    "\n",
    "    # Normalize:\n",
    "    to_normalize = [\"Age\", \"Fee\", \"Quantity\"]\n",
    "    for to_norm in to_normalize:\n",
    "         X[to_norm] = (train[to_norm] - train[to_norm].mean()) / train[to_norm].std()\n",
    "    \n",
    "    return X, y, pet_ids\n",
    "\n",
    "def read_images(image_paths):\n",
    "    def random_image():\n",
    "        return np.random.rand(height, width, 3) * 255\n",
    "    \n",
    "    def read_image(path):\n",
    "        img = np.asarray(Image.open(path).convert(\"RGB\"), dtype=\"int32\" )\n",
    "        return resize(img, (height, width), anti_aliasing=True, mode='constant')    \n",
    "\n",
    "    return np.array([read_image(path) if os.path.isfile(path) else random_image() for path in tqdm(image_paths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "X, y, pet_ids = read_csv_kaggle(os.path.join(data_dir, \"train.csv\"), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 14993/14993 [08:06<00:00, 30.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "f_im_name = \"images.binary\"\n",
    "\n",
    "if not os.path.isfile(f_im_name):\n",
    "    images = read_images([os.path.join(train_image, pet_id + \"-1.jpg\") for pet_id in pet_ids])\n",
    "    \n",
    "    # Standardize:\n",
    "    mean, std = np.mean(images), np.std(images)\n",
    "    images_meanstd = (images - mean)/std\n",
    "    \n",
    "    with open(f_im_name, 'wb') as handle_1, open(\"mnstd\", 'wb') as handle_2:\n",
    "        pickle.dump(images_meanstd, handle_1, protocol=pickle.HIGHEST_PROTOCOL)        \n",
    "        pickle.dump((mean, std), handle_2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f_im_name, 'rb') as handle_1, open(\"mnstd\", 'rb') as handle_2:\n",
    "        images_meanstd = pickle.load(handle_1)\n",
    "        temp = pickle.load(handle_2)\n",
    "        mean, std = temp[0], temp[1]\n",
    "                \n",
    "print(images_meanstd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "X_train_img, X_test_img, X_train_else, X_test_else, y_train, y_test = train_test_split(images_meanstd, \n",
    "                                                                                       X, \n",
    "                                                                                       y, \n",
    "                                                                                       test_size=test_size,\n",
    "                                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Priit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Priit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10794 samples, validate on 1200 samples\n",
      "Epoch 1/7\n",
      "10794/10794 [==============================] - ETA: 32:22 - loss: 1.6136 - acc: 0.25 - ETA: 29:02 - loss: 1.5903 - acc: 0.25 - ETA: 27:28 - loss: 1.5635 - acc: 0.27 - ETA: 26:19 - loss: 1.5915 - acc: 0.27 - ETA: 24:40 - loss: 1.5770 - acc: 0.27 - ETA: 22:41 - loss: 1.5794 - acc: 0.28 - ETA: 20:28 - loss: 1.5642 - acc: 0.28 - ETA: 18:29 - loss: 1.5712 - acc: 0.28 - ETA: 16:56 - loss: 1.5709 - acc: 0.28 - ETA: 15:15 - loss: 1.5617 - acc: 0.29 - ETA: 13:45 - loss: 1.5577 - acc: 0.29 - ETA: 12:06 - loss: 1.5540 - acc: 0.29 - ETA: 10:32 - loss: 1.5480 - acc: 0.30 - ETA: 9:04 - loss: 1.5440 - acc: 0.3057 - ETA: 7:39 - loss: 1.5370 - acc: 0.307 - ETA: 6:18 - loss: 1.5329 - acc: 0.310 - ETA: 5:00 - loss: 1.5296 - acc: 0.313 - ETA: 3:43 - loss: 1.5235 - acc: 0.316 - ETA: 2:29 - loss: 1.5175 - acc: 0.318 - ETA: 1:17 - loss: 1.5195 - acc: 0.319 - ETA: 5s - loss: 1.5150 - acc: 0.3223  - 1607s 149ms/step - loss: 1.5145 - acc: 0.3219 - val_loss: 1.4407 - val_acc: 0.3608\n",
      "Epoch 2/7\n",
      "10794/10794 [==============================] - ETA: 23:22 - loss: 1.4418 - acc: 0.35 - ETA: 21:17 - loss: 1.4321 - acc: 0.34 - ETA: 20:15 - loss: 1.4324 - acc: 0.34 - ETA: 18:50 - loss: 1.4350 - acc: 0.35 - ETA: 17:35 - loss: 1.4346 - acc: 0.35 - ETA: 16:28 - loss: 1.4372 - acc: 0.35 - ETA: 15:20 - loss: 1.4323 - acc: 0.35 - ETA: 14:22 - loss: 1.4289 - acc: 0.34 - ETA: 13:14 - loss: 1.4246 - acc: 0.35 - ETA: 12:09 - loss: 1.4249 - acc: 0.35 - ETA: 11:04 - loss: 1.4227 - acc: 0.35 - ETA: 10:00 - loss: 1.4221 - acc: 0.35 - ETA: 8:54 - loss: 1.4247 - acc: 0.3514 - ETA: 7:50 - loss: 1.4228 - acc: 0.350 - ETA: 42:08 - loss: 1.4206 - acc: 0.35 - ETA: 33:20 - loss: 1.4208 - acc: 0.35 - ETA: 25:25 - loss: 1.4203 - acc: 0.35 - ETA: 18:17 - loss: 1.4176 - acc: 0.35 - ETA: 11:49 - loss: 1.4165 - acc: 0.35 - ETA: 5:53 - loss: 1.4187 - acc: 0.3530 - ETA: 25s - loss: 1.4166 - acc: 0.356 - 6717s 622ms/step - loss: 1.4163 - acc: 0.3564 - val_loss: 1.4254 - val_acc: 0.3383\n",
      "Epoch 3/7\n",
      "10794/10794 [==============================] - ETA: 20:34 - loss: 1.4440 - acc: 0.34 - ETA: 18:57 - loss: 1.4463 - acc: 0.32 - ETA: 17:42 - loss: 1.4355 - acc: 0.34 - ETA: 16:40 - loss: 1.4276 - acc: 0.34 - ETA: 15:40 - loss: 1.4199 - acc: 0.34 - ETA: 14:39 - loss: 1.4180 - acc: 0.35 - ETA: 13:38 - loss: 1.4144 - acc: 0.35 - ETA: 12:44 - loss: 1.4143 - acc: 0.35 - ETA: 11:46 - loss: 1.4085 - acc: 0.35 - ETA: 10:46 - loss: 1.4089 - acc: 0.35 - ETA: 9:46 - loss: 1.4117 - acc: 0.3537 - ETA: 8:49 - loss: 1.4081 - acc: 0.355 - ETA: 7:50 - loss: 1.4071 - acc: 0.355 - ETA: 6:51 - loss: 1.4060 - acc: 0.357 - ETA: 5:52 - loss: 1.4038 - acc: 0.358 - ETA: 4:55 - loss: 1.4045 - acc: 0.359 - ETA: 3:56 - loss: 1.4026 - acc: 0.359 - ETA: 2:58 - loss: 1.4020 - acc: 0.359 - ETA: 2:00 - loss: 1.3990 - acc: 0.360 - ETA: 1:02 - loss: 1.3972 - acc: 0.364 - ETA: 4s - loss: 1.3957 - acc: 0.3664  - 1335s 124ms/step - loss: 1.3962 - acc: 0.3664 - val_loss: 1.4159 - val_acc: 0.3642\n",
      "Epoch 4/7\n",
      "10794/10794 [==============================] - ETA: 20:54 - loss: 1.3633 - acc: 0.36 - ETA: 18:56 - loss: 1.3868 - acc: 0.36 - ETA: 17:39 - loss: 1.3931 - acc: 0.36 - ETA: 16:36 - loss: 1.3954 - acc: 0.36 - ETA: 15:55 - loss: 1.3838 - acc: 0.36 - ETA: 14:51 - loss: 1.3853 - acc: 0.36 - ETA: 13:51 - loss: 1.3816 - acc: 0.36 - ETA: 12:50 - loss: 1.3813 - acc: 0.36 - ETA: 12:03 - loss: 1.3798 - acc: 0.36 - ETA: 11:01 - loss: 1.3796 - acc: 0.37 - ETA: 9:59 - loss: 1.3781 - acc: 0.3727 - ETA: 8:58 - loss: 1.3753 - acc: 0.374 - ETA: 7:57 - loss: 1.3760 - acc: 0.376 - ETA: 6:57 - loss: 1.3751 - acc: 0.378 - ETA: 5:57 - loss: 1.3759 - acc: 0.378 - ETA: 4:58 - loss: 1.3753 - acc: 0.379 - ETA: 4:00 - loss: 1.3756 - acc: 0.380 - ETA: 3:01 - loss: 1.3774 - acc: 0.378 - ETA: 2:02 - loss: 1.3782 - acc: 0.377 - ETA: 1:03 - loss: 1.3785 - acc: 0.376 - ETA: 4s - loss: 1.3793 - acc: 0.3769  - 1362s 126ms/step - loss: 1.3812 - acc: 0.3759 - val_loss: 1.4247 - val_acc: 0.3517\n",
      "Epoch 5/7\n",
      "10794/10794 [==============================] - ETA: 20:02 - loss: 1.3572 - acc: 0.41 - ETA: 18:39 - loss: 1.3968 - acc: 0.38 - ETA: 18:21 - loss: 1.3991 - acc: 0.36 - ETA: 17:13 - loss: 1.4015 - acc: 0.36 - ETA: 16:11 - loss: 1.3957 - acc: 0.37 - ETA: 15:01 - loss: 1.3927 - acc: 0.37 - ETA: 14:06 - loss: 1.3916 - acc: 0.37 - ETA: 13:03 - loss: 1.3911 - acc: 0.36 - ETA: 12:07 - loss: 1.3888 - acc: 0.37 - ETA: 11:05 - loss: 1.3852 - acc: 0.36 - ETA: 10:04 - loss: 1.3844 - acc: 0.36 - ETA: 9:01 - loss: 1.3833 - acc: 0.3690 - ETA: 8:01 - loss: 1.3815 - acc: 0.370 - ETA: 7:02 - loss: 1.3808 - acc: 0.370 - ETA: 6:04 - loss: 1.3812 - acc: 0.371 - ETA: 5:04 - loss: 1.3821 - acc: 0.371 - ETA: 4:04 - loss: 1.3838 - acc: 0.371 - ETA: 3:04 - loss: 1.3842 - acc: 0.370 - ETA: 2:04 - loss: 1.3820 - acc: 0.372 - ETA: 1:04 - loss: 1.3818 - acc: 0.371 - ETA: 4s - loss: 1.3811 - acc: 0.3714  - 1384s 128ms/step - loss: 1.3808 - acc: 0.3717 - val_loss: 1.4079 - val_acc: 0.3575\n",
      "Epoch 6/7\n",
      "10794/10794 [==============================] - ETA: 21:06 - loss: 1.3296 - acc: 0.42 - ETA: 19:01 - loss: 1.3258 - acc: 0.41 - ETA: 17:34 - loss: 1.3200 - acc: 0.41 - ETA: 16:37 - loss: 1.3231 - acc: 0.41 - ETA: 15:36 - loss: 1.3409 - acc: 0.40 - ETA: 14:42 - loss: 1.3448 - acc: 0.40 - ETA: 13:38 - loss: 1.3490 - acc: 0.40 - ETA: 13:00 - loss: 1.3513 - acc: 0.40 - ETA: 11:58 - loss: 1.3548 - acc: 0.39 - ETA: 11:04 - loss: 1.3555 - acc: 0.39 - ETA: 10:10 - loss: 1.3562 - acc: 0.39 - ETA: 9:07 - loss: 1.3590 - acc: 0.3932 - ETA: 8:04 - loss: 1.3582 - acc: 0.393 - ETA: 7:07 - loss: 1.3585 - acc: 0.393 - ETA: 6:05 - loss: 1.3577 - acc: 0.394 - ETA: 5:05 - loss: 1.3609 - acc: 0.392 - ETA: 4:04 - loss: 1.3603 - acc: 0.392 - ETA: 3:03 - loss: 1.3620 - acc: 0.390 - ETA: 2:03 - loss: 1.3601 - acc: 0.390 - ETA: 1:04 - loss: 1.3587 - acc: 0.389 - ETA: 4s - loss: 1.3599 - acc: 0.3870  - 1372s 127ms/step - loss: 1.3598 - acc: 0.3869 - val_loss: 1.4021 - val_acc: 0.3742\n",
      "Epoch 7/7\n",
      "10794/10794 [==============================] - ETA: 20:52 - loss: 1.3467 - acc: 0.38 - ETA: 19:07 - loss: 1.3468 - acc: 0.38 - ETA: 17:56 - loss: 1.3606 - acc: 0.38 - ETA: 17:15 - loss: 1.3495 - acc: 0.39 - ETA: 16:14 - loss: 1.3437 - acc: 0.39 - ETA: 15:07 - loss: 1.3433 - acc: 0.39 - ETA: 13:59 - loss: 1.3417 - acc: 0.39 - ETA: 12:56 - loss: 1.3456 - acc: 0.39 - ETA: 11:56 - loss: 1.3394 - acc: 0.39 - ETA: 10:57 - loss: 1.3395 - acc: 0.39 - ETA: 9:56 - loss: 1.3375 - acc: 0.3968 - ETA: 8:59 - loss: 1.3377 - acc: 0.397 - ETA: 8:00 - loss: 1.3363 - acc: 0.398 - ETA: 7:01 - loss: 1.3364 - acc: 0.399 - ETA: 6:02 - loss: 1.3350 - acc: 0.397 - ETA: 5:01 - loss: 1.3381 - acc: 0.395 - ETA: 4:02 - loss: 1.3400 - acc: 0.394 - ETA: 3:03 - loss: 1.3394 - acc: 0.395 - ETA: 2:04 - loss: 1.3412 - acc: 0.395 - ETA: 1:04 - loss: 1.3411 - acc: 0.395 - ETA: 4s - loss: 1.3424 - acc: 0.3933  - 1391s 129ms/step - loss: 1.3422 - acc: 0.3935 - val_loss: 1.4227 - val_acc: 0.3400\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49618986/neural-network-in-keras-with-two-different-input-types-images-and-values\n",
    "# https://www.learnopencv.com/keras-tutorial-transfer-learning-using-pre-trained-models/\n",
    "\n",
    "transfer = Xception(weights='imagenet', include_top=False, input_shape=(height, width, 3))\n",
    "\n",
    "# Freeze Xception\n",
    "for layer in transfer.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Inputs\n",
    "image_input = Input(shape=(height, width, 3))\n",
    "aux_input = Input(shape=(len(list(X_train_else)),))\n",
    "\n",
    "# Images:\n",
    "transfer = transfer(image_input)\n",
    "transfer = Dense(150, activation='relu')(transfer)\n",
    "flatten = Flatten()(transfer)\n",
    "\n",
    "# Aux input:\n",
    "x = Dense(150, activation='relu')(aux_input)\n",
    "x = Dense(250, activation='relu')(x)\n",
    "x = Dense(350, activation='relu')(x)\n",
    "\n",
    "# Merged:\n",
    "merge = concatenate([flatten, x])\n",
    "x = Dense(500)(merge)\n",
    "x = Dense(450, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "h = Dense(5)(x)\n",
    "\n",
    "# Predictions:\n",
    "predictions = Activation('softmax')(h)\n",
    "\n",
    "model = Model(inputs=[image_input, aux_input], outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit([X_train_img, X_train_else], \n",
    "                    keras.utils.to_categorical(y_train),\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=7, \n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[ModelCheckpoint('test_model.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "train_pred = [np.argmax(pred) for pred in model.predict([X_train_img, X_train_else])]\n",
    "test_predictions = [np.argmax(pred) for pred in model.predict([X_test_img, X_test_else])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa on train: 0.3381\n",
      "Accuracy on train: 0.3951\n",
      "________________\n",
      "Kappa on test: 0.2702\n",
      "Accuracy on test: 0.3451\n"
     ]
    }
   ],
   "source": [
    "print(\"Kappa on train: {}\".format(round(cohen_kappa_score(y_train, train_pred, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on train: {}\".format(round(accuracy_score(y_train, train_pred), 4)))\n",
    "print(\"________________\")\n",
    "print(\"Kappa on test: {}\".format(round(cohen_kappa_score(y_test, test_predictions, weights=\"quadratic\"), 4)))\n",
    "print(\"Accuracy on test: {}\".format(round(accuracy_score(y_test, test_predictions), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3972/3972 [01:55<00:00, 37.38it/s]\n"
     ]
    }
   ],
   "source": [
    "test, _, test_pet_ids = read_csv_kaggle(os.path.join(data_dir, \"test.csv\"), False)\n",
    "test_images = read_images([os.path.join(test_image, pet_id + \"-1.jpg\") for pet_id in test_pet_ids])\n",
    "test_images_std = (test_images - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "loaded = load_model('test_model.h5')\n",
    "test_pred = loaded.predict([test_images_std, test])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PetFinderNN)",
   "language": "python",
   "name": "pycharm-b185692d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
