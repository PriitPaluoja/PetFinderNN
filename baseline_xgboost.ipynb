{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Tests\n",
    "\n",
    "Here we test XGBoost with TFID features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, cohen_kappa_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With kaggle submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "\n",
    "selected_columns = [\"Type\", \"Age\", \"Breed1\", \"Breed2\", \"Gender\", \"Color1\", \"Color2\", \"Color3\",\n",
    "                    \"MaturitySize\", \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\", \"Health\",\n",
    "                    \"Quantity\", \"Fee\", \"State\", \"VideoAmt\", \"PhotoAmt\", \"Description\"]\n",
    "\n",
    "label_column = \"AdoptionSpeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train.csv\n",
    "# TODO: rm n-rows\n",
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), sep=',')\n",
    "pet_ids = train[\"PetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(os.path.join(data_dir, \"test.csv\"), sep=',')\n",
    "test_pet_ids = test[\"PetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3972"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[selected_columns]\n",
    "X_test = test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14993"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df_train, df_test, columns):\n",
    "    result = df_train.copy()\n",
    "    result_2 = df_test.copy()\n",
    "    for feature_name in columns:\n",
    "        max_value = df_train[feature_name].max()\n",
    "        min_value = df_train[feature_name].min()\n",
    "        result[feature_name] = (df_train[feature_name] - min_value) / (max_value - min_value)\n",
    "        result_2[feature_name] = (df_test[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result, result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, X_test_norm = normalize(X, X_test, [\"Age\", \"Fee\"]) #, \"Quantity\", \"VideoAmt\", \"PhotoAmt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(X_train_norm)\n",
    "concated_df = pd.concat([X_train_norm, X_test_norm], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(concated_df, columns=[\"Type\", \"Breed1\", \"Breed2\", \"Gender\", \"Color1\", \"Color2\", \"Color3\", \"MaturitySize\",                                     \n",
    "                                       \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\", \"Health\", \"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummies = X_dummies.iloc[:len_train,]\n",
    "X_test_dummies = X_dummies.iloc[len_train:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "max_features = 500\n",
    "\n",
    "# Vectorizer from https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments?fbclid=IwAR1dRU97Bn8Ldj6KMwMNn6Rm6HQJqMV9aTbQ0jtoqgywZWd_W7fIioDrpVc\n",
    "\n",
    "texts_train = [x.lower() if not isinstance(x, numbers.Real) else \"\" for x in X_train_dummies.Description]\n",
    "# Remove punctuation\n",
    "texts_train = [''.join(c for c in x if c not in string.punctuation) for x in texts_train]\n",
    "# Remove numbers\n",
    "texts_train = [''.join(c for c in x if c not in '0123456789') for x in texts_train]\n",
    "# Trim extra whitespace\n",
    "texts_train = [' '.join(x.split()) for x in texts_train]\n",
    "\n",
    "\n",
    "test_texts = [x.lower() if not isinstance(x, numbers.Real) else \"\" for x in X_test_dummies.Description]\n",
    "# Remove punctuation\n",
    "test_texts = [''.join(c for c in x if c not in string.punctuation) for x in test_texts]\n",
    "# Remove numbers\n",
    "test_texts = [''.join(c for c in x if c not in '0123456789') for x in test_texts]\n",
    "# Trim extra whitespace\n",
    "test_texts = [' '.join(x.split()) for x in test_texts]\n",
    "\n",
    "\n",
    "\n",
    "# Define tokenizer\n",
    "def tokenizer(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "# Create TF-IDF of texts\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, stop_words='english', max_features=max_features, ngram_range=(1,3),\n",
    "                       max_df=0.95, min_df=0.01)\n",
    "sparse_tfidf_texts = tfidf.fit_transform(texts_train)\n",
    "\n",
    "\n",
    "test_sparse_tfidf_texts = tfidf.transform(test_texts)\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(sparse_tfidf_texts.toarray(), columns=tfidf.get_feature_names(), index=X_train_dummies.index)\n",
    "test_df = pd.DataFrame(test_sparse_tfidf_texts.toarray(), columns=tfidf.get_feature_names(), index=X_test_dummies.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_new = pd.concat([X_train_dummies, train_df], axis=1)\n",
    "X_test_new = pd.concat([X_test_dummies, test_df], axis=1)\n",
    "\n",
    "\n",
    "X_train_new = X_train_new.drop(\"Description\", axis=1)\n",
    "X_test_new = X_test_new.drop(\"Description\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for train-test split\n",
    "\n",
    "```\n",
    "best_test_score = -1\n",
    "best_n = None\n",
    "\n",
    "model = XGBClassifier(verbosity=2, max_depth=6)\n",
    "print(\"fitting\")\n",
    "model.fit(X_train_new, y_train)\n",
    "\n",
    "print(\"predicting\")\n",
    "#rf = RandomForestClassifier(n_estimators=n).fit(X_train_new, y_train)\n",
    "pred_test = model.predict(X_test_new)\n",
    "pred_train = model.predict(X_train_new)\n",
    "cohen_kappa = cohen_kappa_score(y_test, pred_test, weights=\"quadratic\")\n",
    "train_score = accuracy_score(y_train, pred_train)\n",
    "test_score = accuracy_score(y_test, pred_test)\n",
    "#print(n)\n",
    "print(\"cohen kappa =\", cohen_kappa)\n",
    "print(\"train score =\", train_score)\n",
    "print(\"test score =\", test_score)\n",
    "\n",
    "\n",
    "fitting\n",
    "predicting\n",
    "cohen kappa = 0.3554781435697453\n",
    "train score = 0.691090995712244\n",
    "test score = 0.41640729212983546\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 900)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape\n",
    "#X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "predicting\n",
      "train score = 0.6407656906556393\n"
     ]
    }
   ],
   "source": [
    "best_test_score = -1\n",
    "best_n = None\n",
    "\n",
    "y_train = train[\"AdoptionSpeed\"]\n",
    "\n",
    "\n",
    "# Max depth hyperparameter was found by finding best results with Kappa and not much overfitting.\n",
    "model = XGBClassifier(verbosity=2, max_depth=6)\n",
    "print(\"fitting\")\n",
    "model.fit(X_train_new, y_train)\n",
    "\n",
    "print(\"predicting\")\n",
    "#rf = RandomForestClassifier(n_estimators=n).fit(X_train_new, y_train)\n",
    "pred_test = model.predict(X_test_new)\n",
    "pred_train = model.predict(X_train_new)\n",
    "#cohen_kappa = cohen_kappa_score(y_test, pred_test, weights=\"quadratic\")\n",
    "train_score = accuracy_score(y_train, pred_train)\n",
    "#test_score = accuracy_score(y_test, pred_test)\n",
    "#print(n)\n",
    "#print(\"cohen kappa =\", cohen_kappa)\n",
    "print(\"train score =\", train_score)\n",
    "#print(\"test score =\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3972"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[\"PetID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"PetID\" : test[\"PetID\"], \"AdoptionSpeed\": pred_test})\n",
    "submission_df.to_csv(\"baseline.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
